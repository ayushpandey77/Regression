{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#theory question"
      ],
      "metadata": {
        "id": "nOy52fy3Vcle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "\n",
        "=A method to model the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line equation:\n",
        "ùëå\n",
        "=\n",
        "ùëö\n",
        "ùëã\n",
        "+\n",
        "ùëê\n",
        "Y=mX+c"
      ],
      "metadata": {
        "id": "S27MV2xuVcjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "=Linearity between X and Y.\n",
        "\n",
        "Residuals are normally distributed.\n",
        "\n",
        "Homoscedasticity (constant variance of residuals).\n",
        "\n",
        "Independence of errors.\n",
        "\n",
        "No extreme outliers."
      ],
      "metadata": {
        "id": "gQiewVqKVcgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What does the coefficient m represent in the equation Y = mX + c?\n",
        "\n",
        "=The slope ‚Üí the change in Y when X increases by 1 unit."
      ],
      "metadata": {
        "id": "X9TkG7LgVcdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What does the intercept c represent in the equation Y = mX + c?\n",
        "\n",
        "=The predicted value of Y when X = 0."
      ],
      "metadata": {
        "id": "MhwJHwEvVcax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        "\n",
        "ùëö\n",
        "=\n",
        "‚àë\n",
        "(\n",
        "ùë•\n",
        "ùëñ\n",
        "‚àí\n",
        "ùë•\n",
        "Àâ\n",
        ")\n",
        "(\n",
        "ùë¶\n",
        "ùëñ\n",
        "‚àí\n",
        "ùë¶\n",
        "Àâ\n",
        ")\n",
        "‚àë\n",
        "(\n",
        "ùë•\n",
        "ùëñ\n",
        "‚àí\n",
        "ùë•\n",
        "Àâ\n",
        ")\n",
        "2\n",
        "m=\n",
        "‚àë(x\n",
        "i\n",
        "\t‚Äã\n",
        "\n",
        "‚àí\n",
        "x\n",
        "Àâ\n",
        ")\n",
        "2\n",
        "‚àë(x\n",
        "i\n",
        "\t‚Äã\n",
        "\n",
        "‚àí\n",
        "x\n",
        "Àâ\n",
        ")(y\n",
        "i\n",
        "\t‚Äã\n",
        "\n",
        "‚àí\n",
        "y\n",
        "Àâ\n",
        "\t‚Äã\n",
        "\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "cD9eufzvVcX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "=To minimize the sum of squared residuals and find the best-fit line."
      ],
      "metadata": {
        "id": "WZl-D6GVVcVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?\n",
        "\n",
        "=R¬≤ = proportion of variance in Y explained by X.\n",
        "\n",
        "R¬≤ = 0 ‚Üí no fit, R¬≤ = 1 ‚Üí perfect fit."
      ],
      "metadata": {
        "id": "sxIKT_OeVcSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. What is Multiple Linear Regression?\n",
        "\n",
        "=Regression with one dependent variable (Y) and two or more independent variables (X‚ÇÅ, X‚ÇÇ, ‚Ä¶)."
      ],
      "metadata": {
        "id": "u7vLtmN8VcPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "\n",
        "=Simple ‚Üí one predictor.\n",
        "\n",
        "Multiple ‚Üí two or more predictors"
      ],
      "metadata": {
        "id": "M8NzpK1AVcM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "\n",
        "=Linearity between predictors and outcome.\n",
        "\n",
        "No multicollinearity.\n",
        "\n",
        "Homoscedasticity.\n",
        "\n",
        "Normal residuals.\n",
        "\n",
        "Independent errors."
      ],
      "metadata": {
        "id": "ANyTh5bIVcKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. What is heteroscedasticity, and how does it affect results?\n",
        "\n",
        "=Residuals have non-constant variance ‚Üí standard errors become unreliable ‚Üí hypothesis tests may be invalid."
      ],
      "metadata": {
        "id": "9FzfKaoEVcHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "=Remove or combine correlated predictors.\n",
        "\n",
        "Use PCA (Principal Component Analysis).\n",
        "\n",
        "Apply Ridge or Lasso regression."
      ],
      "metadata": {
        "id": "MoxOjUKpVcEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. What are some common techniques for transforming categorical variables?\n",
        "\n",
        "=One-hot encoding (dummy variables).\n",
        "\n",
        "Label encoding (for ordinal variables).\n",
        "\n",
        "Binary/target encoding (sometimes used)."
      ],
      "metadata": {
        "id": "aD0zZJZ6VcBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "=They capture the combined effect of two predictors (e.g., study time √ó motivation)."
      ],
      "metadata": {
        "id": "6Mtvnl2wVb_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "=Simple: value of Y when X = 0.\n",
        "\n",
        "Multiple: value of Y when all predictors = 0 (may not always be meaningful)."
      ],
      "metadata": {
        "id": "RD_GMr-aVb8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is the significance of the slope in regression analysis?\n",
        "\n",
        "=It shows how much Y changes for a one-unit increase in X, keeping other predictors constant."
      ],
      "metadata": {
        "id": "7ObEK980Vb5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. How does the intercept in a regression model provide context?\n",
        "\n",
        "=It anchors the regression line, giving the baseline Y when predictors = 0."
      ],
      "metadata": {
        "id": "TXDFy-p6Vb2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What are the limitations of using R¬≤ as a sole measure of model performance?\n",
        "\n",
        "=Always increases with more predictors.\n",
        "\n",
        "Doesn‚Äôt measure predictive accuracy.\n",
        "\n",
        "Doesn‚Äôt detect overfitting."
      ],
      "metadata": {
        "id": "TjR3ycz6VbzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "=It means the estimate is imprecise, likely due to multicollinearity or small sample size."
      ],
      "metadata": {
        "id": "054aka3VVbwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. How can heteroscedasticity be identified in residual plots, and why is it important?\n",
        "\n",
        "=Identified when residuals form a funnel shape.\n",
        "\n",
        "Must be corrected; otherwise, p-values and confidence intervals are invalid."
      ],
      "metadata": {
        "id": "uNhOiM02Vbtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What does it mean if a model has high R¬≤ but low adjusted R¬≤?\n",
        "\n",
        "=The model is overfitted with irrelevant predictors."
      ],
      "metadata": {
        "id": "SK6DJfN9Vbqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "=Ensures predictors are on the same scale.\n",
        "\n",
        "Improves numerical stability and interpretability.\n",
        "\n",
        "Essential for regularization methods (Ridge/Lasso)."
      ],
      "metadata": {
        "id": "1x-TWVKDVbn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. What is polynomial regression?\n",
        "\n",
        "=Regression that models the relationship between X and Y as an nth-degree polynomial."
      ],
      "metadata": {
        "id": "HJgDyUgtVblL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. How does polynomial regression differ from linear regression?\n",
        "\n",
        "=Linear: straight-line relationship.\n",
        "\n",
        "Polynomial: curved relationship (quadratic, cubic, etc.)."
      ],
      "metadata": {
        "id": "Shm0IwivVbiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. When is polynomial regression used?\n",
        "\n",
        "=When data shows a non-linear trend that a straight line cannot capture."
      ],
      "metadata": {
        "id": "5wMhN-xQVbf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. What is the general equation for polynomial regression?\n",
        "\n",
        "\n",
        "\n",
        "ùëå\n",
        "=\n",
        "ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùëã\n",
        "+\n",
        "ùõΩ\n",
        "2\n",
        "ùëã\n",
        "2\n",
        "+\n",
        "‚ãØ\n",
        "+\n",
        "ùõΩ\n",
        "ùëõ\n",
        "ùëã\n",
        "ùëõ\n",
        "+\n",
        "ùúñ\n",
        "Y=Œ≤\n",
        "0\n",
        "\t‚Äã\n",
        "\n",
        "+Œ≤\n",
        "1\n",
        "\t‚Äã\n",
        "\n",
        "X+Œ≤\n",
        "2\n",
        "\t‚Äã\n",
        "\n",
        "X\n",
        "2\n",
        "+‚ãØ+Œ≤\n",
        "n\n",
        "\t‚Äã\n",
        "\n",
        "X\n",
        "n\n",
        "+œµ"
      ],
      "metadata": {
        "id": "xcuDbUm2Vbcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "=Yes, resulting in multiple polynomial regression with cross terms (e.g., X‚ÇÅ¬≤, X‚ÇÅX‚ÇÇ)."
      ],
      "metadata": {
        "id": "45bgEkoQVbZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. What are the limitations of polynomial regression?\n",
        "\n",
        "\n",
        "=Overfitting risk.\n",
        "\n",
        "Hard to interpret coefficients.\n",
        "\n",
        "Sensitive to outliers."
      ],
      "metadata": {
        "id": "u1z_wclRXH7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. What methods can be used to evaluate model fit when selecting polynomial degree?\n",
        "\n",
        "Cross-validation.\n",
        "\n",
        "Adjusted R¬≤.\n",
        "\n",
        "AIC/BIC.\n",
        "\n",
        "Residual plots."
      ],
      "metadata": {
        "id": "gMOKzouJXI19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Why is visualization important in polynomial regression?\n",
        "\n",
        "=Helps check whether the curve fits properly and to detect overfitting."
      ],
      "metadata": {
        "id": "ik13fivIXIZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. How is polynomial regression implemented in Python?\n",
        "\n",
        "=from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [2, 5, 10, 17, 26]\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "print(model.coef_, model.intercept_)\n"
      ],
      "metadata": {
        "id": "xp2Rx__dXUBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8RYZGgZbXYEP"
      }
    }
  ]
}